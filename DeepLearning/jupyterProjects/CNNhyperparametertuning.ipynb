{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4758a021",
   "metadata": {},
   "source": [
    "# CNN hyperparameter tuning \n",
    "- stride 1 filter 3x3\n",
    "- stride 2 filter 3x3\n",
    "- stride 3 filter 3x3\n",
    "- stride 1 filter 2x2\n",
    "- stride 1 filter 4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd60e6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "#show random picture\n",
    "#split the data test and train\n",
    "#take the image data and normalize the data\n",
    "#label encode\n",
    "#define CNN\n",
    "#prediction and actual accuracy\n",
    "#Confusion matrix visulization\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras.layers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import Sequential\n",
    "from keras.regularizers import L2\n",
    "#get data\n",
    "label_data=pd.read_csv('E:\\python\\python_projects\\deepfaceTensorflow\\DeepLearning\\CNN\\datasets\\cifar10Labels.csv',index_col=0)\n",
    "import keras.callbacks\n",
    "# from warnings\n",
    "from mlxtend.evaluate import confusion_matrix,scoring\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from skimage.transform import resize\n",
    "from  vis.visualization import visualize_cam,visualize_saliency,overlay\n",
    "from vis.utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f7cca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            label\n",
      "id               \n",
      "1            frog\n",
      "2           truck\n",
      "3           truck\n",
      "4            deer\n",
      "5      automobile\n",
      "...           ...\n",
      "49996        bird\n",
      "49997        frog\n",
      "49998       truck\n",
      "49999  automobile\n",
      "50000  automobile\n",
      "\n",
      "[50000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "318889ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ytrain,ytest=train_test_split(label_data['label'],test_size=0.2,random_state=42)\n",
    "print(ytrain.shape,ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0676c06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "\n",
    "for i in ytrain.index:\n",
    "    img_path=os.path.join('E:\\python\\python_projects\\deepfaceTensorflow\\DeepLearning\\CNN\\datasets\\cifar10',f'{i}.png')\n",
    "    img=np.array(imageio.imread(img_path)).astype('float32')\n",
    "    temp.append(img)\n",
    "\n",
    "xtrain=np.stack(temp)\n",
    "print(xtrain.shape)\n",
    "temp=[]\n",
    "for i in ytest.index:\n",
    "    img_path=os.path.join('E:\\python\\python_projects\\deepfaceTensorflow\\DeepLearning\\CNN\\datasets\\cifar10',f'{i}.png')\n",
    "    img=np.array(imageio.imread(img_path)).astype('float32')\n",
    "    temp.append(img)\n",
    "xtest=np.stack(temp)\n",
    "print(xtest.shape)\n",
    "\n",
    "\n",
    "xtrain=xtrain/255.\n",
    "xtest=xtest/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa0d9b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]] [[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "lb=LabelEncoder()\n",
    "\n",
    "ytraint=lb.fit_transform(ytrain)\n",
    "ytrain=to_categorical(ytraint)\n",
    "ytestt=lb.fit_transform(ytest)\n",
    "ytest=to_categorical(ytestt)\n",
    "\n",
    "print(ytrain,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89bf191",
   "metadata": {},
   "source": [
    "# stride 1 filter 3X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55befde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (Conv2D)              (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " BN1 (Normalization)         (None, 32, 32, 32)        65        \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling2D)     (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " BN2 (Normalization)         (None, 16, 16, 64)        129       \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling2D)     (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " Flat (Flatten)              (None, 4096)              0         \n",
      "                                                                 \n",
      " pred_layer (Dense)          (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,556\n",
      "Trainable params: 60,362\n",
      "Non-trainable params: 194\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      " 986/1000 [============================>.] - ETA: 0s - loss: 2.8440 - accuracy: 0.3547WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.8288 - accuracy: 0.3562 - val_loss: 1.8297 - val_accuracy: 0.4649\n",
      "Epoch 2/5\n",
      " 996/1000 [============================>.] - ETA: 0s - loss: 1.6753 - accuracy: 0.4931WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6747 - accuracy: 0.4934 - val_loss: 1.6819 - val_accuracy: 0.4850\n",
      "Epoch 3/5\n",
      " 991/1000 [============================>.] - ETA: 0s - loss: 1.4688 - accuracy: 0.5489WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 1.4692 - accuracy: 0.5491 - val_loss: 1.5502 - val_accuracy: 0.5161\n",
      "Epoch 4/5\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 1.3395 - accuracy: 0.5862WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3392 - accuracy: 0.5860 - val_loss: 1.4408 - val_accuracy: 0.5523\n",
      "Epoch 5/5\n",
      " 988/1000 [============================>.] - ETA: 0s - loss: 1.2597 - accuracy: 0.6104WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2599 - accuracy: 0.6101 - val_loss: 1.4233 - val_accuracy: 0.5594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21c860e2b50>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_classes=10\n",
    "model=Sequential([\n",
    "    keras.layers.Conv2D(filters=32,kernel_size=(3,3),padding='same',activation='relu',kernel_regularizer=L2(0.01),input_shape=(32,32,3),name='conv1'),\n",
    "    keras.layers.Normalization(name='BN1'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2),name='maxpool1'),\n",
    "    keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding='same',activation='relu',kernel_regularizer=L2(0.01),input_shape=(32,32,3),name='conv2'),\n",
    "    keras.layers.Normalization(name='BN2'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2),name='maxpool2'),\n",
    "    keras.layers.Flatten(name='Flat'),\n",
    "    keras.layers.Dense(num_classes,activation='softmax',name='pred_layer'),\n",
    "    ])\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer=tf.optimizers.Adam(),metrics=['accuracy'])\n",
    "cpfile=r'cifar10.hdf5'\n",
    "cb_checkpoint=keras.callbacks.ModelCheckpoint(cpfile,monitor='val_acc',verbose=1,save_best_only=True,mode='max')\n",
    "model.fit(xtrain,ytrain,validation_split=0.2,epochs=5,callbacks=[cb_checkpoint])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea276e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "[6 7 5 ... 8 8 8]\n",
      "train accuracy: 60.1075\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[5 8 0 ... 8 7 3]\n",
      "test accuracy: 56.58\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "\n",
    "pred_ytrain=model.predict(xtrain)\n",
    "pred_ytrain=np.argmax(pred_ytrain,axis=1)\n",
    "print(pred_ytrain)\n",
    "print(f'train accuracy: {scoring(ytraint,pred_ytrain,metric=\"accuracy\")*100}')\n",
    "pred_ytest=model.predict(xtest)\n",
    "pred_ytest=np.argmax(pred_ytest,axis=1)\n",
    "print(pred_ytest)\n",
    "print(f'test accuracy: {scoring(ytestt,pred_ytest,metric=\"accuracy\")*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ab9dab",
   "metadata": {},
   "source": [
    "# stride 3 filter 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d946dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
